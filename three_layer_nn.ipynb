{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.44270396  0.0992484   0.59122431]]\n",
      "[[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "在迭代 0 次后，训练损失为 0.308504\n",
      "在迭代 1000 次后，训练损失为 0.0393406\n",
      "在迭代 2000 次后，训练损失为 0.0182158\n",
      "在迭代 3000 次后，训练损失为 0.0104779\n",
      "在迭代 4000 次后，训练损失为 0.00680374\n",
      "在迭代 5000 次后，训练损失为 0.00446512\n",
      "在迭代 6000 次后，训练损失为 0.00296797\n",
      "在迭代 7000 次后，训练损失为 0.00218553\n",
      "在迭代 8000 次后，训练损失为 0.00179452\n",
      "在迭代 9000 次后，训练损失为 0.0013211\n",
      "在迭代 10000 次后，训练损失为 0.000957699\n"
     ]
    }
   ],
   "source": [
    "# 构建三层全连接神经网络\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 10\n",
    "# 设置 batch_size参考：\n",
    "# https://www.zhihu.com/question/32673260/answer/71137399\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "# None 可以根据batch 大小确定维度，在shape的一个维度上使用None\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "y = tf.placeholder(tf.float32,shape=(None,1))\n",
    "\n",
    "# activate function 使用ReLU\n",
    "a = tf.nn.relu(tf.matmul(x,w1))\n",
    "yhat = tf.nn.relu(tf.matmul(a,w2))\n",
    "\n",
    "# 定义交叉熵为损失函数，训练过程使用Adam算法最小化交叉熵\n",
    "cross_entropy = -tf.reduce_mean(y*tf.log(tf.clip_by_value(yhat,1e-10,1.0))) # About gradient cliping\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1) # 返回一个一维随机数组\n",
    "data_size = 512\n",
    "\n",
    "# 生成两个特征，共data_size个样本\n",
    "X = rdm.rand(data_size,2)\n",
    "# 定义规则给出样本标签，所有 x1+x2<1 的样本认为是正样本，其他为负样本。Y，1为正样本\n",
    "Y = [[int(x1+x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    steps=11000\n",
    "    for i in range(steps):\n",
    "        # 选定每一个批量读取的首尾位置，确保在1个epoch内采样训练\n",
    "        start = i * batch_size % data_size\n",
    "        end = min(start + batch_size,data_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y:Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            training_loss= sess.run(cross_entropy,feed_dict={x:X,y:Y})\n",
    "            print(\"在迭代 %d 次后，训练损失为 %g\"%(i,training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
